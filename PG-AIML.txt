Steps are followed for Machine Learning Model Building :- 

Steps_No.1
     ## Import required packages.
          from sklearn import linear_model
          from sklearn.metrics import mean_squared_error
          import pandas as pd
          import numpy as np 
          from sklearn.model_selection import train_test_split

Steps_No.2
     ## Load the dataset.
          # Load the diabetes dataset
          diabetes = pd.read_csv("diabetes.csv")
          diabetes.head()

Steps_No.3
     ## Split data into Feature and Lable.
          diabetes_X = diabetes[["BloodPressure", "Age"]]  # Select specific columns using iloc is diabetes.iloc[:,[2, 7]]
          diabetes_y = diabetes["Glucose"]                # Select glucose column using iloc is diabetes.iloc[:, 1]
          print(diabetes_X.shape, diabetes_y.shape)

Steps_No.4
     ## Split into train and test data with test_size.
          X_train, X_test, y_train, y_test = train_test_split(diabetes_X, diabetes_y, test_size=0.2)

Steps_No.5
     ## Check the shape.
          X_train.shape, X_test.shape, y_train.shape, y_test.shape

Steps_No.6
     ## There are a few ways to find the best fit line. One of the approaches is the Ordinary Least Squares (OLS) method which 
     is an intutive mathematical method. 
     **Note:** Refer the following [link](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) 
     for Linear Regression from sklearn...

     # Create a linear regression object
          regr = linear_model.LinearRegression()
     # Train the model using the training sets
          regr.fit(X_train, y_train)
     # Make predictions using the testing set
          diabetes_y_pred = regr.predict(X_test)

Steps_No.7
     # For retrieving the slope use 'regr.coef_'. As we have taken two variables, we will get two coefficients m1 and m2
          print('Coefficients: ', regr.coef_)
     # To retrieve the intercept
          print('Intercept: ', regr.intercept_)
     # Calculate the root mean squared error
          print("Root mean squared error: %.2f" % np.sqrt(mean_squared_error(y_test, diabetes_y_pred)))

Steps_No.8
     ## Find the Test Score
          print(regr.score(X_test, y_test))

=====================================================================================================================================================

## 1. Handle Category Data. 
## 2. Increase or Manual Hyper-parameter-tuining.

Step_No_1: Import Required Library
     import numpy as np
     import pandas as pd
     import matplotlib.pyplot as plt
     from sklearn.model_selection import train_test_split
     import seaborn as sns
     from sklearn.preprocessing import StandardScaler
     from sklearn.linear_model import SGDClassifier
     from sklearn.metrics import accuracy_score
     import warnings
     warnings.filterwarnings("ignore")

Step_No_2: Import Dataset
     Link = "//dataset_url//"
     dataset = pd.read_csv(Link)

Step_No_3: Display Head
     dataset.head()

Step_No_4: Check Missing Value or Missing Value Handling
     dataset.isna().sum() // Missing Value sum
     dataset = dataset.dropna()  OR dataset.dropna(inplace = True) // Drop all null Value

Step_No_5: Chack data-type to handle the Category data
     dataset.dtypes // display the data-type for each column
     dataset['column_name'].unique() // display the unique Value contains in that selected column

Step_No_6: Replacing the Category data to numeric data
     dataset['column_name'] = dataset['column_name'].replace(['No.of categories values in a rows'],[No.of numeric values need to replace with categories value in rows])
     dataset.head()

Step_No_7: In "Step_No_6", we used ".replace" method wich is difficult for large date in column so, best practices to use
          Label-Encoder which is pre library in sk-learn.
      "from sklearn.preprocessing import LabelEncoder" // Importing Library
      le = LabelEncoder() // Creating Object for Label-Encoder
      dataset['column_name'] = le.fit_transform(dataset['column_name'])  // Category to numeric transforming

Step_No_8: Split data in to dependent and independent variable
     X = dataset[['Put all the independent variable or columns']] // independent column
     Y = dataset['Put dependent variable or column'] // dependent column

Step_No_9: Train and Test Split
     x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state = 41) // spliting data into train and test spliting

Step_No_10_A: Checking Accuracy score for the model "Default-Hyper-tuining" and "Manual-Hyper-tuining"
     ## "Default-Hyper-tuining"
     lc = SGDClassifier() // Object Creating
     lc.fit(x_train,y_train) // Fitting the train data to SGDClassifier
     y_pred = lc.predict(x_test)
     print(' Accuracy ',lc.score(x_test,y_test)) // Print Accuracy Score for default-Hyper-tuining
     print(lc.get_params().items()) // Display or Get all parameters of SGDClassifier

Step_No_11: Manual Accuracy Score Testing and Checking for that needed library Import
     "from sklearn.model_selection import GridSearchCV" // Import Library
     print(lc.get_params().items()) // Display or Get all parameters of SGDClassifier // Print all parameters
     params = {
    "loss":['hinge', 'log_loss', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error', 'huber', 'epsilon_insensitive'],
    "max_iter":[1000,2000,2500,3000]
     }

     clf = SGDClassifier() // Object Creating for SGDClassifier
     grid = GridSearchCV(clf,param_grid=params,cv=10) // Object Creating for GridSearchCV and pass the required parameter for accuracy_score Check
     grid.fit(x_train,y_train) // Fitting the train data to GridSearchCV
     print(grid.best_params_)
     print(grid.best_estimator_)
     print(grid.best_score_)

Step_No_10_B: Checking Accuracy score for the model "Default-Hyper-tuining" and "Manual-Hyper-tuining"
     ## "Manual-Hyper-tuining"
     lc = SGDClassifier(loss= 'log', max_iter=2000) // Object Creating and pass the parameters from "Step_No_11"
     lc.fit(x_train,y_train) // Fitting the train data to SGDClassifier
     y_pred = lc.predict(x_test)
     print(' Accuracy ',lc.score(x_test,y_test)) // Print Accuracy Score for default-Hyper-tuining
     print(lc.get_params().items()) // Display or Get all parameters of SGDClassifier  // Optional

=====================================================================================================================================================